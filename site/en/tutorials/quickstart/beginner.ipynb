{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for beginners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/beginner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "This short introduction uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
        "\n",
        "1. Load a prebuilt dataset.\n",
        "1. Build a neural network machine learning model that classifies images.\n",
        "2. Train this neural network.\n",
        "3. Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This tutorial is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook. Python programs are run directly in the browser—a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. To run all the code in the notebook, select **Runtime** > **Run all**. To run the code cells one at a time, hover over each cell and select the **Run cell** icon.\n",
        "\n",
        "![Run cell icon](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/images/beginner/run_cell_icon.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RcOCIhlaJo-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Object detection API an YAML"
      ],
      "metadata": {
        "id": "-OYMUJ70JSxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-object-detection-api\n",
        "!pip install tensorflow pillow pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxZ3A2eLJQ2V",
        "outputId": "0701cdb5-0513-4688-c4b9-42df66b3f2fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-object-detection-api\n",
            "  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/577.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m553.0/577.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (11.1.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (3.10.0)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (3.0.12)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (5.29.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (5.3.1)\n",
            "Collecting jupyter (from tensorflow-object-detection-api)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (2.18.0)\n",
            "Collecting contextlib2 (from tensorflow-object-detection-api)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-object-detection-api) (0.45.1)\n",
            "Collecting twine (from tensorflow-object-detection-api)\n",
            "  Downloading twine-6.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->tensorflow-object-detection-api) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->tensorflow-object-detection-api) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->tensorflow-object-detection-api) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter->tensorflow-object-detection-api) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter->tensorflow-object-detection-api) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.37.1)\n",
            "Collecting readme-renderer>=35.0 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from twine->tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from twine->tensorflow-object-detection-api) (2.3.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine->tensorflow-object-detection-api) (23.5.0)\n",
            "Collecting rfc3986>=1.4.0 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from twine->tensorflow-object-detection-api) (13.9.4)\n",
            "Collecting id (from twine->tensorflow-object-detection-api)\n",
            "  Downloading id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->tensorflow-object-detection-api) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->tensorflow-object-detection-api) (0.14.1)\n",
            "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->tensorflow-object-detection-api)\n",
            "  Downloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: docutils>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (0.21.2)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->twine->tensorflow-object-detection-api) (3.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->tensorflow-object-detection-api) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->tensorflow-object-detection-api) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->tensorflow-object-detection-api) (3.1.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (3.0.50)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->tensorflow-object-detection-api) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->tensorflow-object-detection-api) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (0.14.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter->tensorflow-object-detection-api) (4.3.7)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->tensorflow-object-detection-api) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (4.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->tensorflow-object-detection-api) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter->tensorflow-object-detection-api) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->tensorflow-object-detection-api) (2.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading twine-6.1.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
            "Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading id-1.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.0/739.0 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844489 sha256=86139a37b66baf36b149aa7843bca07674c4565bb6bcca41e0b5cdab3d4bfc42\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/4f/d0/e711451dedf65c9f1d357a34438b4d26fb24a819a22d58a9a6\n",
            "Successfully built tensorflow-object-detection-api\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3986, rfc3339-validator, python-json-logger, overrides, nh3, json5, jedi, fqdn, contextlib2, async-lru, readme-renderer, jupyter-server-terminals, jupyter-client, id, arrow, twine, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, tensorflow-object-detection-api\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.5 contextlib2-21.6.0 fqdn-1.5.1 id-1.5.0 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 nh3-0.2.21 overrides-7.7.0 python-json-logger-3.3.0 readme-renderer-44.0 rfc3339-validator-0.1.4 rfc3986-2.0.0 rfc3986-validator-0.1.1 tensorflow-object-detection-api-0.1.1 twine-6.1.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "lDBYQYVUJWj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWXPkM6oVB6S",
        "outputId": "f9448968-7555-4a99-9755-c4e43c893dd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## Set up TensorFlow\n",
        "\n",
        "Import TensorFlow into your program to get started:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import yaml"
      ],
      "metadata": {
        "id": "VaK6OtgFOLjD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "then run the rest of the code"
      ],
      "metadata": {
        "id": "ngPqaxX8OMny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0trJmd6DjqBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dabee335-5e26-4a59-a7b2-b3e5588eaa9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 1/50\n",
            "    104/Unknown \u001b[1m1496s\u001b[0m 14s/step - accuracy: 0.0579 - loss: 91195.7969Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "    181/Unknown \u001b[1m2608s\u001b[0m 14s/step - accuracy: 0.0532 - loss: 431705504.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 5363449344.0000, Accuracy: 0.0396, Val Loss: 162743533568.0000, Val Accuracy: 0.0000\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2624s\u001b[0m 14s/step - accuracy: 0.0531 - loss: 458803008.0000 - val_accuracy: 0.0000e+00 - val_loss: 162743533568.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 519ms/step - accuracy: 0.0214 - loss: 290581020672.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.0198 - loss: 778874781696.0000Epoch 2/50, Loss: 2345488875520.0000, Accuracy: 0.0176, Val Loss: 21350672498688.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 515ms/step - accuracy: 0.0198 - loss: 787482542080.0000 - val_accuracy: 0.0000e+00 - val_loss: 21350672498688.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 530ms/step - accuracy: 0.0213 - loss: 11846038847488.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.0207 - loss: 16105661792256.0000Epoch 3/50, Loss: 27013918228480.0000, Accuracy: 0.0201, Val Loss: 101189328830464.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0207 - loss: 16165597347840.0000 - val_accuracy: 0.0000e+00 - val_loss: 101189328830464.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 515ms/step - accuracy: 0.0158 - loss: 72582036455424.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.0168 - loss: 86013657481216.0000Epoch 4/50, Loss: 118916546297856.0000, Accuracy: 0.0185, Val Loss: 439214260879360.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 514ms/step - accuracy: 0.0168 - loss: 86194440372224.0000 - val_accuracy: 0.0000e+00 - val_loss: 439214260879360.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 533ms/step - accuracy: 0.0233 - loss: 226589186981888.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.0221 - loss: 253421055639552.0000Epoch 5/50, Loss: 317277119447040.0000, Accuracy: 0.0201, Val Loss: 1054380111429632.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 537ms/step - accuracy: 0.0221 - loss: 253771917557760.0000 - val_accuracy: 0.0000e+00 - val_loss: 1054380111429632.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 538ms/step - accuracy: 0.0140 - loss: 574280412692480.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.0153 - loss: 612752246702080.0000Epoch 6/50, Loss: 722202240483328.0000, Accuracy: 0.0175, Val Loss: 2664699715911680.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 534ms/step - accuracy: 0.0153 - loss: 613353609232384.0000 - val_accuracy: 0.0000e+00 - val_loss: 2664699715911680.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 521ms/step - accuracy: 0.0263 - loss: 1092943951691776.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - accuracy: 0.0228 - loss: 1170302352490496.0000Epoch 7/50, Loss: 1330525167943680.0000, Accuracy: 0.0182, Val Loss: 3485074439798784.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 525ms/step - accuracy: 0.0228 - loss: 1171182686568448.0000 - val_accuracy: 0.0000e+00 - val_loss: 3485074439798784.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 533ms/step - accuracy: 0.0150 - loss: 1881452836814848.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.0169 - loss: 1967687592837120.0000Epoch 8/50, Loss: 2171767393091584.0000, Accuracy: 0.0195, Val Loss: 6768554925883392.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0169 - loss: 1968808847736832.0000 - val_accuracy: 0.0000e+00 - val_loss: 6768554925883392.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 522ms/step - accuracy: 0.0152 - loss: 3258017235599360.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.0164 - loss: 3303311692267520.0000Epoch 9/50, Loss: 3467190464413696.0000, Accuracy: 0.0183, Val Loss: 8025804596314112.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 534ms/step - accuracy: 0.0165 - loss: 3304212024786944.0000 - val_accuracy: 0.0000e+00 - val_loss: 8025804596314112.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 556ms/step - accuracy: 0.0226 - loss: 4314992849453056.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.0219 - loss: 4591477879472128.0000Epoch 10/50, Loss: 5102275118759936.0000, Accuracy: 0.0199, Val Loss: 13175076320968704.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 783ms/step - accuracy: 0.0219 - loss: 4594284103729152.0000 - val_accuracy: 0.0000e+00 - val_loss: 13175076320968704.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 549ms/step - accuracy: 0.0289 - loss: 5824580706893824.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.0269 - loss: 6135521843609600.0000Epoch 11/50, Loss: 6814924466552832.0000, Accuracy: 0.0244, Val Loss: 15258218137649152.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 546ms/step - accuracy: 0.0269 - loss: 6139254707060736.0000 - val_accuracy: 0.0000e+00 - val_loss: 15258218137649152.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 526ms/step - accuracy: 0.0161 - loss: 8663678643601408.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.0170 - loss: 8965087637274624.0000Epoch 12/50, Loss: 9448667131936768.0000, Accuracy: 0.0188, Val Loss: 25037763107618816.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 525ms/step - accuracy: 0.0170 - loss: 8967744611418112.0000 - val_accuracy: 0.0000e+00 - val_loss: 25037763107618816.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 534ms/step - accuracy: 0.0169 - loss: 11755898867286016.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.0178 - loss: 11903614603755520.0000Epoch 13/50, Loss: 12281327986409472.0000, Accuracy: 0.0192, Val Loss: 27688258292940800.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 537ms/step - accuracy: 0.0178 - loss: 11905690146701312.0000 - val_accuracy: 0.0000e+00 - val_loss: 27688258292940800.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 519ms/step - accuracy: 0.0166 - loss: 13919707685978112.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.0179 - loss: 14272378188070912.0000Epoch 14/50, Loss: 15286492981100544.0000, Accuracy: 0.0204, Val Loss: 34642188302286848.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 523ms/step - accuracy: 0.0180 - loss: 14277949834395648.0000 - val_accuracy: 0.0000e+00 - val_loss: 34642188302286848.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 509ms/step - accuracy: 0.0223 - loss: 17633719451910144.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.0201 - loss: 18182986713268224.0000Epoch 15/50, Loss: 19492945296097280.0000, Accuracy: 0.0168, Val Loss: 54486229994962944.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 510ms/step - accuracy: 0.0201 - loss: 18190185078456320.0000 - val_accuracy: 0.0000e+00 - val_loss: 54486229994962944.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 529ms/step - accuracy: 0.0254 - loss: 21907174330466304.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.0243 - loss: 22198471897382912.0000Epoch 16/50, Loss: 22843335467073536.0000, Accuracy: 0.0218, Val Loss: 53274662670434304.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 541ms/step - accuracy: 0.0243 - loss: 22202015245402112.0000 - val_accuracy: 0.0000e+00 - val_loss: 53274662670434304.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 508ms/step - accuracy: 0.0283 - loss: 26751594645159936.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.0268 - loss: 27416444845162496.0000Epoch 17/50, Loss: 29039521576255488.0000, Accuracy: 0.0249, Val Loss: 75311487031181312.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 510ms/step - accuracy: 0.0268 - loss: 27425361197268992.0000 - val_accuracy: 0.0000e+00 - val_loss: 75311487031181312.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 533ms/step - accuracy: 0.0122 - loss: 33152148183187456.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.0141 - loss: 33235809851146240.0000Epoch 18/50, Loss: 33904089582534656.0000, Accuracy: 0.0180, Val Loss: 88687621508694016.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 534ms/step - accuracy: 0.0142 - loss: 33239482048184320.0000 - val_accuracy: 0.0000e+00 - val_loss: 88687621508694016.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 516ms/step - accuracy: 0.0161 - loss: 39542913490747392.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - accuracy: 0.0180 - loss: 39767840928038912.0000Epoch 19/50, Loss: 40791645167288320.0000, Accuracy: 0.0209, Val Loss: 105269055719473152.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 519ms/step - accuracy: 0.0180 - loss: 39773467335196672.0000 - val_accuracy: 0.0000e+00 - val_loss: 105269055719473152.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 532ms/step - accuracy: 0.0204 - loss: 45357010719342592.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.0199 - loss: 45839022014070784.0000Epoch 20/50, Loss: 47451253952741376.0000, Accuracy: 0.0192, Val Loss: 102469759244697600.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 534ms/step - accuracy: 0.0199 - loss: 45847882531602432.0000 - val_accuracy: 0.0000e+00 - val_loss: 102469759244697600.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 520ms/step - accuracy: 0.0224 - loss: 54243633062215680.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.0215 - loss: 54335150225358848.0000Epoch 21/50, Loss: 54989896514797568.0000, Accuracy: 0.0207, Val Loss: 126125030361792512.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0215 - loss: 54338749407952896.0000 - val_accuracy: 0.0000e+00 - val_loss: 126125030361792512.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 537ms/step - accuracy: 0.0176 - loss: 59938918610501632.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.0172 - loss: 60937133434601472.0000Epoch 22/50, Loss: 63334043013349376.0000, Accuracy: 0.0166, Val Loss: 160833760592396288.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 783ms/step - accuracy: 0.0172 - loss: 60950301804331008.0000 - val_accuracy: 0.1000 - val_loss: 160833760592396288.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 516ms/step - accuracy: 0.0249 - loss: 72975016232222720.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.0228 - loss: 72804085123776512.0000Epoch 23/50, Loss: 73850906092765184.0000, Accuracy: 0.0194, Val Loss: 166395365283594240.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 783ms/step - accuracy: 0.0228 - loss: 72809840379953152.0000 - val_accuracy: 0.0000e+00 - val_loss: 166395365283594240.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.0208 - loss: 75876301000409088.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.0198 - loss: 77421424075079680.0000Epoch 24/50, Loss: 80874569191129088.0000, Accuracy: 0.0187, Val Loss: 189631121175085056.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0198 - loss: 77440399240593408.0000 - val_accuracy: 0.0000e+00 - val_loss: 189631121175085056.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 547ms/step - accuracy: 0.0175 - loss: 96617307958149120.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.0186 - loss: 96120500501086208.0000Epoch 25/50, Loss: 95199891441057792.0000, Accuracy: 0.0194, Val Loss: 234047765984837632.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 543ms/step - accuracy: 0.0186 - loss: 96115441029611520.0000 - val_accuracy: 0.0000e+00 - val_loss: 234047765984837632.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 556ms/step - accuracy: 0.0242 - loss: 100130874674118656.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.0233 - loss: 101826965849243648.0000Epoch 26/50, Loss: 106514321357406208.0000, Accuracy: 0.0214, Val Loss: 258129149397303296.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 551ms/step - accuracy: 0.0233 - loss: 101852718473150464.0000 - val_accuracy: 0.0000e+00 - val_loss: 258129149397303296.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.0186 - loss: 116827405418496000.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.0194 - loss: 117527450728005632.0000Epoch 27/50, Loss: 118631334632488960.0000, Accuracy: 0.0183, Val Loss: 240353018493534208.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 529ms/step - accuracy: 0.0194 - loss: 117533515221827584.0000 - val_accuracy: 0.0000e+00 - val_loss: 240353018493534208.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 510ms/step - accuracy: 0.0246 - loss: 121377914678673408.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.0220 - loss: 123966182230327296.0000Epoch 28/50, Loss: 128170620205662208.0000, Accuracy: 0.0180, Val Loss: 257420514153201664.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 510ms/step - accuracy: 0.0220 - loss: 123989289154379776.0000 - val_accuracy: 0.1000 - val_loss: 257420514153201664.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 526ms/step - accuracy: 0.0250 - loss: 134484746116792320.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.0230 - loss: 137666844436725760.0000Epoch 29/50, Loss: 143129879628480512.0000, Accuracy: 0.0199, Val Loss: 292487685174460416.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 523ms/step - accuracy: 0.0230 - loss: 137696857668190208.0000 - val_accuracy: 0.0000e+00 - val_loss: 292487685174460416.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 522ms/step - accuracy: 0.0163 - loss: 153810509810892800.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.0171 - loss: 153694030297825280.0000Epoch 30/50, Loss: 153075812705239040.0000, Accuracy: 0.0201, Val Loss: 322841696524042240.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 522ms/step - accuracy: 0.0171 - loss: 153690628683726848.0000 - val_accuracy: 0.1000 - val_loss: 322841696524042240.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 538ms/step - accuracy: 0.0172 - loss: 173458799779119104.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.0177 - loss: 173681227545444352.0000Epoch 31/50, Loss: 177584253305880576.0000, Accuracy: 0.0194, Val Loss: 356156005492457472.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 533ms/step - accuracy: 0.0177 - loss: 173702668022185984.0000 - val_accuracy: 0.0000e+00 - val_loss: 356156005492457472.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 524ms/step - accuracy: 0.0169 - loss: 179246543088386048.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.0171 - loss: 182528258879782912.0000Epoch 32/50, Loss: 191174096766107648.0000, Accuracy: 0.0166, Val Loss: 519531544910495744.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 522ms/step - accuracy: 0.0171 - loss: 182575761218076672.0000 - val_accuracy: 0.0000e+00 - val_loss: 519531544910495744.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 520ms/step - accuracy: 0.0173 - loss: 195203824061775872.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.0173 - loss: 200844851288211456.0000Epoch 33/50, Loss: 210396068280532992.0000, Accuracy: 0.0185, Val Loss: 436949013254635520.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0173 - loss: 200897318608699392.0000 - val_accuracy: 0.0000e+00 - val_loss: 436949013254635520.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.0195 - loss: 214205326314962944.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.0205 - loss: 216353187920084992.0000Epoch 34/50, Loss: 220237573522456576.0000, Accuracy: 0.0213, Val Loss: 444581822974656512.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 783ms/step - accuracy: 0.0205 - loss: 216374542497480704.0000 - val_accuracy: 0.0000e+00 - val_loss: 444581822974656512.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 530ms/step - accuracy: 0.0208 - loss: 230619986945638400.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.0208 - loss: 232148771964715008.0000Epoch 35/50, Loss: 240644457794371584.0000, Accuracy: 0.0204, Val Loss: 472878407550500864.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 526ms/step - accuracy: 0.0208 - loss: 232195466849157120.0000 - val_accuracy: 0.0000e+00 - val_loss: 472878407550500864.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.0168 - loss: 256452754942197760.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.0181 - loss: 258866251684642816.0000Epoch 36/50, Loss: 264753706954653696.0000, Accuracy: 0.0192, Val Loss: 815401327851995136.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 520ms/step - accuracy: 0.0181 - loss: 258898601378316288.0000 - val_accuracy: 0.0000e+00 - val_loss: 815401327851995136.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.0172 - loss: 293189173592981504.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.0176 - loss: 289476603862319104.0000Epoch 37/50, Loss: 284622174126342144.0000, Accuracy: 0.0176, Val Loss: 738831338093674496.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 524ms/step - accuracy: 0.0176 - loss: 289449906345607168.0000 - val_accuracy: 0.1000 - val_loss: 738831338093674496.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 518ms/step - accuracy: 0.0216 - loss: 297689612124422144.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.0203 - loss: 302742555248820224.0000Epoch 38/50, Loss: 321347425862156288.0000, Accuracy: 0.0183, Val Loss: 840080553532194816.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 513ms/step - accuracy: 0.0203 - loss: 302844775470465024.0000 - val_accuracy: 0.0000e+00 - val_loss: 840080553532194816.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 520ms/step - accuracy: 0.0211 - loss: 339012591990865920.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - accuracy: 0.0203 - loss: 336609368810192896.0000Epoch 39/50, Loss: 333883920003104768.0000, Accuracy: 0.0182, Val Loss: 712115885598310400.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 518ms/step - accuracy: 0.0203 - loss: 336594387964264448.0000 - val_accuracy: 0.1000 - val_loss: 712115885598310400.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 525ms/step - accuracy: 0.0336 - loss: 328190545715265536.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.0293 - loss: 337202795851546624.0000Epoch 40/50, Loss: 351556542195040256.0000, Accuracy: 0.0226, Val Loss: 813487284266467328.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 526ms/step - accuracy: 0.0293 - loss: 337281651451101184.0000 - val_accuracy: 0.0000e+00 - val_loss: 813487284266467328.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 524ms/step - accuracy: 0.0219 - loss: 356036227444506624.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.0220 - loss: 360741690534789120.0000Epoch 41/50, Loss: 373015744994082816.0000, Accuracy: 0.0207, Val Loss: 743889984934641664.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 522ms/step - accuracy: 0.0220 - loss: 360809104341467136.0000 - val_accuracy: 0.0000e+00 - val_loss: 743889984934641664.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 530ms/step - accuracy: 0.0168 - loss: 396059172250058752.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.0186 - loss: 400450621691396096.0000Epoch 42/50, Loss: 411424778528751616.0000, Accuracy: 0.0207, Val Loss: 920287727755198464.0000, Val Accuracy: 0.1000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 532ms/step - accuracy: 0.0186 - loss: 400510923032231936.0000 - val_accuracy: 0.1000 - val_loss: 920287727755198464.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 511ms/step - accuracy: 0.0306 - loss: 431618615242915840.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.0269 - loss: 430701725624565760.0000Epoch 43/50, Loss: 436168463078129664.0000, Accuracy: 0.0206, Val Loss: 973286799554117632.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0269 - loss: 430731790395637760.0000 - val_accuracy: 0.0000e+00 - val_loss: 973286799554117632.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.0261 - loss: 456680952005918720.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.0240 - loss: 459053801177874432.0000Epoch 44/50, Loss: 464978553943883776.0000, Accuracy: 0.0218, Val Loss: 1204710288981491712.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 526ms/step - accuracy: 0.0240 - loss: 459086339850108928.0000 - val_accuracy: 0.0000e+00 - val_loss: 1204710288981491712.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 547ms/step - accuracy: 0.0223 - loss: 472638988893552640.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.0228 - loss: 473474377212493824.0000Epoch 45/50, Loss: 478764505610846208.0000, Accuracy: 0.0235, Val Loss: 988718651408384000.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 532ms/step - accuracy: 0.0228 - loss: 473503445551153152.0000 - val_accuracy: 0.0000e+00 - val_loss: 988718651408384000.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 512ms/step - accuracy: 0.0171 - loss: 517209960468185088.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.0174 - loss: 522829701836701696.0000Epoch 46/50, Loss: 536893658146799616.0000, Accuracy: 0.0194, Val Loss: 1254953572324343808.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 516ms/step - accuracy: 0.0174 - loss: 522906976888291328.0000 - val_accuracy: 0.0000e+00 - val_loss: 1254953572324343808.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 518ms/step - accuracy: 0.0236 - loss: 554192686903459840.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.0220 - loss: 549084184082120704.0000Epoch 47/50, Loss: 539648450170454016.0000, Accuracy: 0.0192, Val Loss: 1130639214275198976.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 849ms/step - accuracy: 0.0220 - loss: 549032335236923392.0000 - val_accuracy: 0.0000e+00 - val_loss: 1130639214275198976.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 525ms/step - accuracy: 0.0224 - loss: 594876884873904128.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.0210 - loss: 594749753841942528.0000Epoch 48/50, Loss: 588805312945848320.0000, Accuracy: 0.0187, Val Loss: 985085040356491264.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0210 - loss: 594717112090492928.0000 - val_accuracy: 0.0000e+00 - val_loss: 985085040356491264.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 514ms/step - accuracy: 0.0237 - loss: 613527625737961472.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.0210 - loss: 618729002932109312.0000Epoch 49/50, Loss: 639202390477635584.0000, Accuracy: 0.0166, Val Loss: 1279627437885358080.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 783ms/step - accuracy: 0.0210 - loss: 618841496715526144.0000 - val_accuracy: 0.0000e+00 - val_loss: 1279627437885358080.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m103/181\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 512ms/step - accuracy: 0.0241 - loss: 658998822457835520.0000Annotation file not found: /content/drive/MyDrive/cards_training/train/labels_voc/150002502_jpg.rf.0daef79388bf6bda71149bb6c464027f (1).xml. Skipping this file.\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.0224 - loss: 657460880568483840.0000Epoch 50/50, Loss: 658137904853286912.0000, Accuracy: 0.0204, Val Loss: 1589679134118772736.0000, Val Accuracy: 0.0000\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 784ms/step - accuracy: 0.0224 - loss: 657464591420227584.0000 - val_accuracy: 0.0000e+00 - val_loss: 1589679134118772736.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/content/drive/MyDrive/cards_training/saved_model/my_model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a19e35792fd8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_yaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model trained successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a19e35792fd8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_yaml, batch_size, epochs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/cards_training/saved_model/my_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Convert the trained model to TensorFlow Lite format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/content/drive/MyDrive/cards_training/saved_model/my_model."
          ]
        }
      ],
      "source": [
        "# Define your model architecture\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load class names from label_map\n",
        "def load_class_names(label_map):\n",
        "    with open(label_map, 'r') as file:\n",
        "        data = yaml.safe_load(file)\n",
        "        class_names = data['names']\n",
        "    return class_names\n",
        "\n",
        "# Parse annotation file\n",
        "def parse_annotation(annotation_path, class_names, num_classes):\n",
        "    try:\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "        label = np.zeros(num_classes)\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            class_id = class_names.index(class_name)\n",
        "            label[class_id] = 1\n",
        "        return label\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Annotation file not found: {annotation_path}. Skipping this file.\")\n",
        "        return None\n",
        "\n",
        "# Data generator\n",
        "def data_generator(image_files, images_dir, annotations_dir, class_names, batch_size, input_shape):\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    def generator():\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(images_dir, image_file)\n",
        "            annotation_file = os.path.splitext(image_file)[0] + \".xml\"\n",
        "            annotation_path = os.path.join(annotations_dir, annotation_file)\n",
        "\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=input_shape[:2])\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "\n",
        "            label = parse_annotation(annotation_path, class_names, num_classes)\n",
        "            if label is not None:\n",
        "                yield image, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
        "        tf.TensorSpec(shape=input_shape, dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n",
        "    ))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Train your model\n",
        "def train_model(data_yaml, batch_size=64, epochs=1):\n",
        "    with open(data_yaml, 'r') as file:\n",
        "        data = yaml.safe_load(file)\n",
        "\n",
        "    class_names = data['names']\n",
        "    num_classes = len(class_names)\n",
        "    input_shape = (640, 640, 3)  # Update this to match your image dimensions\n",
        "\n",
        "    train_images_dir = os.path.join('/content/drive/MyDrive/cards_training', data['train'])\n",
        "    train_annotations_dir = os.path.join('/content/drive/MyDrive/cards_training/train/labels_voc')\n",
        "    val_images_dir = os.path.join('/content/drive/MyDrive/cards_training', data['val'])\n",
        "    val_annotations_dir = os.path.join('/content/drive/MyDrive/cards_training/valid/labels_voc')\n",
        "\n",
        "    train_image_files = [f for f in os.listdir(train_images_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
        "    val_image_files = [f for f in os.listdir(val_images_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
        "\n",
        "    train_dataset = data_generator(train_image_files, train_images_dir, train_annotations_dir, class_names, batch_size, input_shape)\n",
        "    val_dataset = data_generator(val_image_files, val_images_dir, val_annotations_dir, class_names, batch_size, input_shape)\n",
        "\n",
        "    model = create_model(input_shape, num_classes)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Add progress printing during training\n",
        "    class PrintProgress(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            logs = logs or {}\n",
        "            print(f\"Epoch {epoch + 1}/{self.params['epochs']}, Loss: {logs.get('loss', 0):.4f}, Accuracy: {logs.get('accuracy', 0):.4f}, Val Loss: {logs.get('val_loss', 0):.4f}, Val Accuracy: {logs.get('val_accuracy', 0):.4f}\")\n",
        "\n",
        "    model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, callbacks=[PrintProgress()])\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save('/content/drive/MyDrive/cards_training/saved_model/my_model.keras')\n",
        "\n",
        "# Convert the trained model to TensorFlow Lite format\n",
        "def convert_to_tflite():\n",
        "    # Load the trained model\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/cards_training/saved_model/my_model.keras')\n",
        "\n",
        "    # Convert the model to TensorFlow Lite format\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TensorFlow Lite model\n",
        "    with open('/content/drive/MyDrive/cards_training/saved_model/model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_yaml = '/content/drive/MyDrive/cards_training/data.yaml'\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    train_model(data_yaml)\n",
        "    print(\"Model trained successfully.\")\n",
        "\n",
        "    print(\"Converting the model to TensorFlow Lite format...\")\n",
        "    convert_to_tflite()\n",
        "    print(\"Model converted and saved successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "beginner.ipynb",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}